{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNovoG9W1dtszh/YVLcF+9f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/know2001/ask_divya/blob/dani-in_progress/dani_scraper_notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BeautifulSoup4 Scraper Notes"
      ],
      "metadata": {
        "id": "4FhS9CjkI6H-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import urllib.parse\n",
        "import pandas as pd\n",
        "import csv\n",
        "import numpy as np\n",
        "import re"
      ],
      "metadata": {
        "id": "dblEmx_aNp2F"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Soup"
      ],
      "metadata": {
        "id": "932ddE1BI3f8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_soup(url):\n",
        "    page = requests.get(url) # gets status code of a web page\n",
        "    soup = BeautifulSoup(page.text, 'html.parser') # Parsed HTML code\n",
        "    return soup"
      ],
      "metadata": {
        "id": "xhzHY-shOdO9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Links (Simple Spider)\n",
        "BS4 has two search methods, `find()` and `find_all()`. The first will give you the first element that meets the search condition, the later will give you a list of all the findings. In HTML the a tag defines a hyperlink, in this case we want to fish all the urls that have the base url in common, to get all the documentation about immigration.\n",
        "\n",
        "\n",
        "The url is stored by the href attribute. It is worth noting that in HTML you use HTML's `<base>` tag to specify the base url for all elements that use the `href` attribute. Now, any tag with an `href` or `src` attribute that is empty, it will automatically go to the url you specified in the base tag by default. We are also going to parse the urls extracted from all the hyperlinks:"
      ],
      "metadata": {
        "id": "ChVyO9bU2cKB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        ">>> url ='https://cat.example/list;meow?breed=siberian#pawsize'\n",
        ">>> urllib.parse.urlparse(url)\n",
        "ParseResult(scheme='https', netloc='cat.example', path='/list', params='meow', query='breed=siberian', fragment='pawsize')\n",
        "```\n",
        "```\n",
        ">>> url ='https://cat.example/list;meow?breed=siberian#pawsize'\n",
        ">>> parsed_url = urllib.parse.urlparse(url)\n",
        ">>> parsed_url.fragment\n",
        "pawsize\n",
        "```\n"
      ],
      "metadata": {
        "id": "iOTQ6dsv9scd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One the url parser joins the base url only if the relative url is missing one in the scheme. There are some urls that are already absolute and do have a base url. Usually the href URLs are relative. In that case `urllib.parser.urljoin()` will not join a new base_url. Check the next two examples:"
      ],
      "metadata": {
        "id": "wj4ke7yH_mEJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When they both have a base url, and it differs, url2 keeps its base url:\n",
        "```\n",
        "urllib.parse.urljoin('http://BASE_URL1/%7Eguido/Python.html', 'http://BASE_URL2/FAQ.html')\n",
        ">>> http://BASE_URL2/FAQ.html\n",
        "```\n",
        "When the second url is relative, it acquires the base url from url1\n",
        "```\n",
        "urllib.parse.urljoin('http://BASE_URL1/%7Eguido/Python.html', 'FAQ.html')\n",
        ">>> http://BASE_URL1/%7Eguido/FAQ.html\n",
        "```"
      ],
      "metadata": {
        "id": "BruTWLceo1Vx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_links(soup, base_url):\n",
        "    links = []\n",
        "    for link in soup.find_all('a', href=True):\n",
        "        url = link[\"href\"] # get url from href attribute\n",
        "        # Resolve relative links\n",
        "        url = urllib.parse.urljoin(base_url, url) #joins relative link to base_url\n",
        "        # Avoid repeating links just because they have a fragment\n",
        "        fragment = urllib.parse.urlparse(url).fragment\n",
        "        url = url.replace(('#'+fragment),'')\n",
        "        if url.startswith(base_url) and url not in links:\n",
        "            links.append(url)\n",
        "    return links"
      ],
      "metadata": {
        "id": "wZfh7nr6OgZV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Page Title\n",
        "It could be useful to get the title for the contents we are going to collect"
      ],
      "metadata": {
        "id": "iwPIdFXyhIpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_title(soup):\n",
        "    title = soup.find('h1').text.strip()\n",
        "    return title"
      ],
      "metadata": {
        "id": "IanxYCoOhko6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Text\n",
        "We are going to extract teh content of each page ignoring non-text. We do this targeting the paragraph tags `<p>`. The function will be given a soup (parsed html script), and it will write the contents of all the paragraphs in a text file.\n",
        "```\n",
        ">>> soup = get_soup('https://www.uscis.gov/working-in-the-united-states/\n",
        ">>> temporary-workers/e-1-treaty-traders')\n",
        ">>> acc_headers = soup.find_all('div',class_='accordion__header cke-active')\n",
        ">>> for i in acc_headers:\n",
        ">>>    print(i['class'],i.get_text) # see how the class key has is a list of two values\n",
        "['accordion__header', 'cke-active'] <bound method PageElement.get_text of <div class=\"accordion__header cke-active\" tabindex=\"0\">Who May File for Change of Status to E-1 Classification</div>>\n",
        "['accordion__header', 'cke-active'] <bound method PageElement.get_text of <div class=\"accordion__header cke-active\" tabindex=\"0\">How to Obtain E-1 Classification if Outside the United States</div>>\n",
        "['accordion__header', 'cke-active'] <bound method PageElement.get_text of <div class=\"accordion__header cke-active\" tabindex=\"0\">General Qualifications of a Treaty Trader</div>>\n",
        "['accordion__header', 'cke-active'] <bound method PageElement.get_text of <div class=\"accordion__header cke-active\" tabindex=\"0\">General Qualifications of the Employee of a Treaty Trader</div>>\n",
        "['accordion__header', 'cke-active'] <bound method PageElement.get_text of <div class=\"accordion__header cke-active\" tabindex=\"0\">Period of Stay</div>>\n",
        "['accordion__header', 'cke-active'] <bound method PageElement.get_text of <div class=\"accordion__header cke-active\" tabindex=\"0\">Terms and Conditions of E-1 Status</div>>\n",
        "['accordion__header', 'cke-active'] <bound method PageElement.get_text of <div class=\"accordion__header cke-active\" tabindex=\"0\">Family of E-1 Treaty Traders and Employees</div>>\n",
        "['accordion__header', 'cke-active'] <bound method PageElement.get_text of <div class=\"accordion__header cke-active\" tabindex=\"0\">More Information</div>>\n",
        "```\n"
      ],
      "metadata": {
        "id": "SRsxcS6BJ7Xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_row(url, soup):\n",
        "    title = get_title(soup)\n",
        "    url = url\n",
        "    text = ''\n",
        "    main = soup.find('main')\n",
        "\n",
        "    for element in main.find_all():\n",
        "        if element.name == 'ul'or element.name == 'p':\n",
        "            text = '\\n'.join([text, element.get_text()])\n",
        "        elif element.has_attr('class'):\n",
        "            if len(element['class'])>1:\n",
        "                if element['class'][0]=='accordion__header':\n",
        "                    text = '\\n'.join([text, element.get_text()])\n",
        "\n",
        "    row = [title, url, text]\n",
        "    return row"
      ],
      "metadata": {
        "id": "_svc1HZFJ7Cp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scraper\n",
        "The scraper is going to visit all the relative urls and extract the useful contents from the paragraphs of each page. It will write the text on an output file, a csv.\n",
        "\n",
        "When you open a file you usually use with open(), this method will automatically close the file after you are done reading or writing. Open takes three attributes, the file name, the mode, and the encoding (automatic). You are usually reading or writing on a file, `r` will select reading mode, `w` will select writing mode. It is worth mentioning the modes:\n",
        "*   w+: Opens a file in read and write mode. It creates a new file if it does not exist, if it exists, it erases the contents of the file and the file pointer starts from the beginning.\n",
        "*   rw+: Opens a file in read and write mode. File pointer starts at the beginning of the file."
      ],
      "metadata": {
        "id": "Pg55IclULH5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"https://www.uscis.gov/working-in-the-united-states\"\n",
        "output_file = \"text.csv\"\n",
        "soup = get_soup(base_url)\n",
        "links = get_links(soup, base_url)"
      ],
      "metadata": {
        "id": "pjDg-S6rFg0a"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scraper(base_url, output_file):\n",
        "    visited = set()\n",
        "    to_visit = [base_url]\n",
        "    data = []\n",
        "\n",
        "    i=0\n",
        "    while to_visit:\n",
        "        # get url from to_visit\n",
        "        url = to_visit.pop() # removes and returns last element of the list\n",
        "        # confirm it is not in visited if it is skip to next iteration using continue\n",
        "        if url in visited:\n",
        "            continue\n",
        "        i+=1\n",
        "        if i%5==0:\n",
        "            print(f'{i} pages scraped')\n",
        "\n",
        "        # add to visited\n",
        "        visited.add(url)\n",
        "        # get soup\n",
        "        soup = get_soup(url)\n",
        "        # get page title and text from soup and create a new row which has dict format\n",
        "        row = get_row(url, soup)\n",
        "        # write new row in the csv\n",
        "        data.append(row)\n",
        "        # get links from soup\n",
        "        links = get_links(soup, base_url)\n",
        "        # append links to to_visit list if they are not in the visited set\n",
        "        to_visit.extend(link for link in links if link not in visited)\n",
        "\n",
        "    print(f'{i} Pages scraped in total')\n",
        "    columns = ['title', 'url', 'text']\n",
        "    df = pd.DataFrame(data, columns=columns)\n",
        "    return df\n",
        "\n",
        "df = scraper(base_url, output_file)"
      ],
      "metadata": {
        "id": "0yb6SEdR8aKj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e117ea7-f467-4967-e7ef-771961bcf476"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 pages scraped\n",
            "10 pages scraped\n",
            "15 pages scraped\n",
            "20 pages scraped\n",
            "25 pages scraped\n",
            "30 pages scraped\n",
            "35 pages scraped\n",
            "40 pages scraped\n",
            "45 pages scraped\n",
            "50 pages scraped\n",
            "55 pages scraped\n",
            "60 pages scraped\n",
            "65 pages scraped\n",
            "70 pages scraped\n",
            "75 pages scraped\n",
            "80 pages scraped\n",
            "85 pages scraped\n",
            "90 pages scraped\n",
            "90 Pages scraped in total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to make sure we can save the DataFrame into a CSV, and then load it back without breaking the shape (row x column)."
      ],
      "metadata": {
        "id": "H1I4sXO6mUAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('data.csv', index = False)\n",
        "df1 = pd.read_csv('data.csv')\n",
        "df1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "aNG-1waFM-Pk",
        "outputId": "f6f03616-f853-4e95-95ef-880f32a0d957"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                title  \\\n",
              "0                        Working in the United States   \n",
              "1                           Petition Process Overview   \n",
              "2                                 Report Labor Abuses   \n",
              "3   Options for Nonimmigrant Workers Following Ter...   \n",
              "4   Employment Authorization in Compelling Circums...   \n",
              "..                                                ...   \n",
              "85  Questions and Answers: EB-5 Immigrant Investor...   \n",
              "86     Questions and Answers: EB-5 Further Deployment   \n",
              "87  EB-5 Questions and Answers: EB-5 Reform and In...   \n",
              "88                                    EB-5 What's New   \n",
              "89            EB-5 Regional Center Compliance Reviews   \n",
              "\n",
              "                                                  url  \\\n",
              "0   https://www.uscis.gov/working-in-the-united-st...   \n",
              "1   https://www.uscis.gov/working-in-the-united-st...   \n",
              "2   https://www.uscis.gov/working-in-the-united-st...   \n",
              "3   https://www.uscis.gov/working-in-the-united-st...   \n",
              "4   https://www.uscis.gov/working-in-the-united-st...   \n",
              "..                                                ...   \n",
              "85  https://www.uscis.gov/working-in-the-united-st...   \n",
              "86  https://www.uscis.gov/working-in-the-united-st...   \n",
              "87  https://www.uscis.gov/working-in-the-united-st...   \n",
              "88  https://www.uscis.gov/working-in-the-united-st...   \n",
              "89  https://www.uscis.gov/working-in-the-united-st...   \n",
              "\n",
              "                                                 text  \n",
              "0   \\nMany noncitizens want to come to the United ...  \n",
              "1   \\nIf you would like to come to the United Stat...  \n",
              "2   \\nWe are committed to helping protect the righ...  \n",
              "3   \\nWhen nonimmigrant workers are laid off, they...  \n",
              "4   \\nThis temporary employment authorization may ...  \n",
              "..                                                ...  \n",
              "85  \\nQuestions and Answers: Visa Availability App...  \n",
              "86  \\nA1. For now, Form I-924A does not separately...  \n",
              "87  \\nEntities seeking to be designated as a regio...  \n",
              "88  \\nThis page provides the latest information on...  \n",
              "89  \\nThis page in Simplified Chinese.  (PDF, 95.3...  \n",
              "\n",
              "[90 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-ea592949-6c92-4326-ab1a-8d5bdf9bfce7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>url</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Working in the United States</td>\n",
              "      <td>https://www.uscis.gov/working-in-the-united-st...</td>\n",
              "      <td>\\nMany noncitizens want to come to the United ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Petition Process Overview</td>\n",
              "      <td>https://www.uscis.gov/working-in-the-united-st...</td>\n",
              "      <td>\\nIf you would like to come to the United Stat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Report Labor Abuses</td>\n",
              "      <td>https://www.uscis.gov/working-in-the-united-st...</td>\n",
              "      <td>\\nWe are committed to helping protect the righ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Options for Nonimmigrant Workers Following Ter...</td>\n",
              "      <td>https://www.uscis.gov/working-in-the-united-st...</td>\n",
              "      <td>\\nWhen nonimmigrant workers are laid off, they...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Employment Authorization in Compelling Circums...</td>\n",
              "      <td>https://www.uscis.gov/working-in-the-united-st...</td>\n",
              "      <td>\\nThis temporary employment authorization may ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>Questions and Answers: EB-5 Immigrant Investor...</td>\n",
              "      <td>https://www.uscis.gov/working-in-the-united-st...</td>\n",
              "      <td>\\nQuestions and Answers: Visa Availability App...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>Questions and Answers: EB-5 Further Deployment</td>\n",
              "      <td>https://www.uscis.gov/working-in-the-united-st...</td>\n",
              "      <td>\\nA1. For now, Form I-924A does not separately...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>EB-5 Questions and Answers: EB-5 Reform and In...</td>\n",
              "      <td>https://www.uscis.gov/working-in-the-united-st...</td>\n",
              "      <td>\\nEntities seeking to be designated as a regio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>EB-5 What's New</td>\n",
              "      <td>https://www.uscis.gov/working-in-the-united-st...</td>\n",
              "      <td>\\nThis page provides the latest information on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>EB-5 Regional Center Compliance Reviews</td>\n",
              "      <td>https://www.uscis.gov/working-in-the-united-st...</td>\n",
              "      <td>\\nThis page in Simplified Chinese.  (PDF, 95.3...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea592949-6c92-4326-ab1a-8d5bdf9bfce7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-9a311e9b-1ab3-44a0-afd5-49035766871e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9a311e9b-1ab3-44a0-afd5-49035766871e')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-9a311e9b-1ab3-44a0-afd5-49035766871e button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ea592949-6c92-4326-ab1a-8d5bdf9bfce7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ea592949-6c92-4326-ab1a-8d5bdf9bfce7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for duplicates:"
      ],
      "metadata": {
        "id": "ukkIrPOEmzhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{sum(df1.duplicated(subset='text'))} duplicates\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeIvo596m2-U",
        "outputId": "9b4abcfa-1628-440d-b00a-389e206df5e2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 duplicates\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning"
      ],
      "metadata": {
        "id": "YRrZFGq23XO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_unwanted_text(df, unwanted_text):\n",
        "   df['text'] = df['text'].apply(lambda x: x.replace(unwanted_text, '', 1) if x.starstswith(unwanted_text) else x)\n",
        "   return df"
      ],
      "metadata": {
        "id": "Q7vjOXpY4cOT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_patterns(df, pattern_list):\n",
        "    words_removed = []\n",
        "    for i, text in enumerate(df['text']):\n",
        "        #print(f'**************Text {i}****************')\n",
        "        matched_search = True\n",
        "        while matched_search is True:\n",
        "            matched_search = False\n",
        "            for pattern in pattern_list:\n",
        "                result = re.search(pattern, df.loc[i, 'text'], flags=0)\n",
        "                if result!=None:\n",
        "                    #print(f'match: {result[0]}')\n",
        "                    matched_search = True\n",
        "                    words_removed.append(result[0])\n",
        "                    df.loc[i, 'text'] = df.loc[i, 'text'].replace(result[0], '')\n",
        "    print(f'{len(words_removed)} words were removed ({len(set(words_removed))} different words): \\n{set(words_removed)}')\n",
        "    return df\n",
        "\n",
        "pattern_list = [\"\\(PDF, \\d+\\.\\d* KB\\)\", \"\\(PDF, \\d+\\.\\d* MB\\)\", \"\\(PDF\\)\"]\n",
        "df2 = remove_patterns(df1.copy(), pattern_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-5Z_DL3KiEL",
        "outputId": "50fde0c0-1e70-46e6-b5ad-38dc5ae774cc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76 words were removed (52 different words): \n",
            "{'(PDF, 280.01 KB)', '(PDF, 400.77 KB)', '(PDF, 357.48 KB)', '(PDF, 428.48 KB)', '(PDF, 641.66 KB)', '(PDF, 238.48 KB)', '(PDF, 1.29 MB)', '(PDF, 314.97 KB)', '(PDF, 231.19 KB)', '(PDF, 361.57 KB)', '(PDF, 1.12 MB)', '(PDF, 315.88 KB)', '(PDF, 272.13 KB)', '(PDF, 262.77 KB)', '(PDF, 476.13 KB)', '(PDF, 5.73 MB)', '(PDF)', '(PDF, 250.08 KB)', '(PDF, 151.74 KB)', '(PDF, 540.72 KB)', '(PDF, 95.33 KB)', '(PDF, 249.12 KB)', '(PDF, 399.14 KB)', '(PDF, 1.3 MB)', '(PDF, 221.65 KB)', '(PDF, 10.99 MB)', '(PDF, 367.63 KB)', '(PDF, 70.28 KB)', '(PDF, 596.67 KB)', '(PDF, 416.01 KB)', '(PDF, 618.16 KB)', '(PDF, 276.55 KB)', '(PDF, 270.61 KB)', '(PDF, 790.07 KB)', '(PDF, 225.48 KB)', '(PDF, 228.14 KB)', '(PDF, 253.39 KB)', '(PDF, 322.1 KB)', '(PDF, 766.7 KB)', '(PDF, 370.8 KB)', '(PDF, 198.94 KB)', '(PDF, 379.71 KB)', '(PDF, 268.06 KB)', '(PDF, 94.21 KB)', '(PDF, 123.38 KB)', '(PDF, 1.13 MB)', '(PDF, 1015.37 KB)', '(PDF, 160.67 KB)', '(PDF, 347.4 KB)', '(PDF, 324.11 KB)', '(PDF, 125.43 KB)', '(PDF, 208.25 KB)'}\n"
          ]
        }
      ]
    }
  ]
}